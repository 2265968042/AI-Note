# KL散度

## 定义

KL散度是一种衡量两个概率分布P和Q的差异的方法；

对于连续随机变量的概率分布来说，KL散度公式为：$D_{K L}(p | q)=\int_{x} p(x) \log \frac{p(x)}{q(x)} d x$

对于离散随机遍历的概率分布来说，KL散度的公式为：$D_{K L}(p | q)=\sum_{x} p(x) \log \frac{p(x)}{q(x)}$

机器学习和深度学习中使用的都是离散随机变量的概率分布。

## KL散度的数学定义

KL散度不是凭空定义的，它有清晰的数学来源，来自信息论中对“信息损失（信息差距）”的度量。

信息论中，一个概率事件$x$的最优编码长度是：$l(x)=-logp(x)$

$p(x)$ 的大小是从0~1。这意味着，可能性越高，$p(x)$ 越大，越接近1，编码越短。可能性越低，$p(x)$ 越小，越接近0，编码越长。

概率分布是一种描述“世界如何运作”的数学工具。例如离散分布：

$P(X=1)=0.2,P(X=2)=0.3,P(X=3)=0.5$ 。代表的含义是事件1的概率是20%，事件2的概率是30%，事件3的概率是50%。所有概率之和必须是1。

#### “真实分布”和“模型分布”

假设：

真实概率分布是$p(x)$ 。我们假设（或模型）使用的概率分布是$q(x)$。如果我们用$q(x)$来编码来自$p(x)$的数据。**这里预期说是编码，不如说是替代**KL 散度的本质是替代误差（q 代替 p 的损失）。  但在信息论的数学推导中，这种替代误差表现为“编码长度的增加”。

如果我们用q(x)来编码来自p(x)的数据，就会导致额外的平均编码成本。

真实的编码成本是：

$$
\mathbb{E}_{x \sim p}\left[-\log p(x)\right]=\sum_x p(x)·(-logp(x))
$$

因为真实编码成本=单个事件的编码码长的期望值。事件出现的概率不同，所以每个事件加权然后求平均值。

使用$q(x)$的编码成本就是：

$$
\mathbb{E}_{x \sim p}\left[-\log q(x)\right]
$$

额外的编码损失就是：

$$
\mathbb{E}_{x \sim p}\left[-\log p(x)\right]-\mathbb{E}_{x \sim p}\left[-\log q(x)\right]
$$

可以得到下面的推导：

$$
\begin{matrix}
\mathbb{E}_{x \sim p}\left[-\log p(x)\right]-
\mathbb{E}_{x \sim p}\left[-\log q(x)\right] \\
=\\

\sum_x p(x)·(-\log p(x))-\sum_x p(x)·(-\log q(x))\\
=\\
\sum_x p(x)·\log \frac{ p(x)}{ q(x)}\\
=\\
D_{K L}(p | q)
\end{matrix}
$$

这里有一个需要认真思考的点是为什么$\mathbb{E}_{x \sim p}\left[-\log q(x)\right]$

是$\sum_x p(x)·-\log q(x)$ 而不是$\sum_x q(x)·-\log q(x)$ 呢？这里是个很关键的问题。

因为期望必须按照实际发生的概率分布来加权，而实际发生的数据来自真实分布$p$,而不是模型$q$。

要想搞清楚$\sum_x p(x)·-\log q(x)$ 是什么，先要搞清楚$\sum_x p(x)·-\log q(x)$ 是什么呢？
它代表的是真实编码成本=单个事件的真实编码码长的期望值。$-\log p(x)$ 是真实编码码长。

而$-log q(x)$ 是模拟编码码长。那它模拟的是谁的呢？就是模拟的真实的事件的码长，而真实的事件的概率是$p(x)$ 的。

所以我们肯定要用真实的概率去算模拟的码长的数学期望的。

而我们可以通过对样本的抽样，来获取真实事件的概率$p(x)$了。那既然我们都可以知道真实事件的概率$p(x)$ 了我们这样做还有什么意义呢？

是有意义的。我们其实是希望通过这些已经发生的真实事件的样本，来推测没有发生的事件的概率的。如果我们最后能让我们针对已经发生的真实事件模拟的$q(x)$无限去接近$p(x)$。这个时候我们就可以相信我们模拟的$q(x)$对未发生的事件的预测将来也会无限去逼近未发生事件的真实值了。

KL散度就可以理解为模拟成本-真实成本，考虑到信息论的定理，也可以理解为错误成本-最优成本。所以错误成本就是模拟成本，真实成本就是最优成本。

**这样我们就讲明白了什么是KL散度了。**

机器学习和深度学习中使用的都是离散随机变量的概率分布，下面将讨论离散情况下的KL散度。

## 在机器学习中KL散度的作用

机器学习的目标就是：希望模型学到的分布$p_{model}$ 与该任务的真实分布$P_{real}$ 一致。

问题在于该任务的真实分布$P_{real}$ 是无法获取到的，能够获取到的是训练集的分布$P_{train}$ ，我们一般认为训练数据是从总体中独立同分布采样出来的，基于该条件下，就可以认为训练集的分布$P_{train}$ 与真实分布$P_{real}$ 是一致的。这样机器学习的目标就是：希望模型学到的分布$P_{model}$与训练集的分布$P_{train}$ 一致。

然后剩下的问题就是如何评估这两个分布是否一致了。答案是使用KL散度进行评估。因为KL散度的定义就是衡量两个概率分布p和q的差异。两个分布越相近，KL散度越小。两个分布的差异越大，KL散度也越大。当两个分布相同时，KL散度为0。

## 熵、KL散度、交叉熵

### 熵

熵衡量的是：一个随机变量（或概率分布）的平均不确定性/平均信息量。

不是某一个事件的，而是整个分布的性质。整个分布可能有很多个事件。

熵的定义是：

$$
H(X)=-\sum_x p(x)\log p(x)
$$

$p(x)$代表事件$x$ 出现的概率

$-\log p(x)$ 代表事件x的信息量

对所有事件求加权平均代表平均信息量。

### KL散度

上面已经说明了什么是KL散度了。从真实分布 P的角度看，使用分布 Q去近似 P，会多损失多少信息。

### 交叉熵

交叉熵：用一个概率分布$q$去描述（编码）来自另一个分布$p$的数据时，所需要的平均信息量。

数学公式定义：

$$
\begin{matrix}
H(p,q)=\mathbb{E}_{x \sim p} \left[ -\log q(x) \right]
=
\sum_x p(x)(-\log q(x))



\end{matrix}
$$

交叉熵是用错误分布$q$去编码真实分布$p$时的平均代价。

三者之间的关系就是

$$
H(p,q)=H(p)+D_{K L}(p | q)
$$

## 机器学习当中为什么多用交叉熵而不是用KL散度呢？

机器学习就是将模型分布$P_{model}$学到与训练分布$P_{train}$ 一致的过程。而衡量两个分布是否一致最直接的评估方式就是KL散度，那么为什么机器学习中常用交叉熵而不是KL散度呢？

$$
D_{KL}(p|q)=H(p|q)-H(p)
$$

将上述公式放到机器学习场景当中，公式中概率分布$q$就是需要学习才能得到的模型分布$P_{model}$，公式中的概率分布$p$就是训练集分布$P_{train}$

在机器学习中，训练集是固定的，所以训练集的熵$H(p)$也是固定的，不随着模型的优化过程而变化。即在机器学习的应用场景下$H(p)$是常数。此时使用$D_{KL}(p|q)$ 对模型优化与使用$H(p,q)$对模型优化是等级的。而且使用交叉熵$H(p,q)$ 时还能少计算一项，节省计算资源。



## KL散度的性质

正定性：$D_{K L}(p | q) \geqslant 0$ 

不对称性：$D_{K L}(p | q)!=D_{K L}(q | p)$

由于KL散度不具有对称性，所以KL散度不是一种距离。

一般来说距离要满足三个条件：正定性、对称性、三角不等式。



## 正则化相关

L1、L2和KL的根本区别不在于“公式不同”，而在于它们的约束的是不同层级的对象。

L1、L2约束的是参数空间。

KL散度约束的是输出分布/函数空间。
